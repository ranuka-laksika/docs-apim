# AI Gateway Safety Categories Overview

AI Gateway provides comprehensive safety and guardrail mechanisms to ensure responsible AI usage. This section covers the various safety categories and their configurations.

## Safety Categories

The AI Gateway implements several safety categories to protect against various risks:

### LLM Safety

The [LLM Safety](../../../design/api-security/configuring-api-security-audit.md) category focuses on protecting against large language model-specific risks and ensuring safe interactions with AI models.

### PII Safety  

The [PII Safety](../../../administer/managing-users-and-roles/introduction-to-user-management.md) category provides protection mechanisms for personally identifiable information handling and privacy compliance.

## Configuration

Each safety category can be configured independently to meet your organization's security requirements and compliance needs.

For more information on configuring AI Gateway safety features, refer to the main [API Security documentation](../../../design/api-security/configuring-api-security-audit.md).
